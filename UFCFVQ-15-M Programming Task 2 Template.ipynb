{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFCFVQ-15-M Programming for Data Science\n",
    "# Programming Task 2\n",
    "\n",
    "## Student Id: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement FR2.1 - Read CSV data from a file (with a header row) into memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataFrame2a = pd.read_csv ('task2a.csv')\n",
    "print(dataFrame2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement FR2.2 - Read CSV data from a file (without a header row) into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#read the 2nd file without header with column name 'id_student', 'click_events'\n",
    "dataFrame2b = pd.read_csv(\"task2b.csv\",names=['id_student', 'click_events'], header=None) \n",
    "print(dataFrame2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement FR2.3 - Merge the data from two Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataFrame2a = pd.read_csv(\"task2a.csv\")\n",
    "#read the 2nd file without header\n",
    "dataFrame2b = pd.read_csv(\"task2b.csv\",names=['id_student', 'click_events'], header=None) \n",
    "#using the merge function to merge the 2 dataFrames\n",
    "dataFrameMerged = pd.merge(dataFrame2a, dataFrame2b, on=['id_student'] )\n",
    "print(dataFrameMerged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement FR2.4 - Remove any rows that contain missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataFrame2a = pd.read_csv(\"task2a.csv\")\n",
    "#read the 2nd file without header\n",
    "dataFrame2b = pd.read_csv(\"task2b.csv\",names=['id_student', 'click_events'], header=None) \n",
    "#using the merge function to merge the 2 dataFrames\n",
    "dataFrameMerged = pd.merge(dataFrame2a, dataFrame2b, on=['id_student'] )\n",
    "#  Remove any rows that contain missing values using dropna()function  \n",
    "dataFrameMerged = dataFrameMerged.dropna()\n",
    "print(dataFrameMerged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement FR2.5 - Filter out unnecessary rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataFrame2a = pd.read_csv(\"task2a.csv\")\n",
    "#read the 2nd file without header\n",
    "dataFrame2b = pd.read_csv(\"task2b.csv\",names=['id_student', 'click_events'], header=None) \n",
    "#using the merge function to merge the 2 dataFrames\n",
    "dataFrameMerged = pd.merge(dataFrame2a, dataFrame2b, on=['id_student'] )\n",
    "#  Remove any rows that contain missing values using dropna() function  \n",
    "dataFrameMerged.dropna()\n",
    "#Remove all rows from the DataFrame where click_event is smaller than 10  \n",
    "dataFrameMerged = dataFrameMerged[dataFrameMerged.click_events >= 10]\n",
    "print(dataFrameMerged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement FR2.6 - Rename the score column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataFrame2a = pd.read_csv(\"task2a.csv\")\n",
    "#read the 2nd file without header\n",
    "dataFrame2b = pd.read_csv(\"task2b.csv\",names=['id_student', 'click_events'], header=None) \n",
    "#using the merge function to merge the 2 dataFrames\n",
    "dataFrameMerged = pd.merge(dataFrame2a, dataFrame2b, on=['id_student'] )\n",
    "#  Remove any rows that contain missing values using dropna() function  \n",
    "dataFrameMerged.dropna()\n",
    "#Remove all rows from the DataFrame where click_event is smaller than 10  \n",
    "dataFrameMerged = dataFrameMerged[dataFrameMerged.click_events >= 10]\n",
    "#Rename the score column to final_mark\n",
    "dataFrameMerged = dataFrameMerged.rename(columns={'score': 'final_mark'})\n",
    "print(dataFrameMerged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement FR2.7 - Remove unnecessary column(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataFrame2a = pd.read_csv(\"task2a.csv\")\n",
    "#read the 2nd file without header\n",
    "dataFrame2b = pd.read_csv(\"task2b.csv\",names=['id_student', 'click_events'], header=None) \n",
    "#using the merge function to merge the 2 dataFrames\n",
    "dataFrameMerged = pd.merge(dataFrame2a, dataFrame2b, on=['id_student'] )\n",
    "#  Remove any rows that contain missing values using dropna() function  \n",
    "dataFrameMerged.dropna()\n",
    "#Remove all rows from the DataFrame where click_event is smaller than 10  \n",
    "dataFrameMerged = dataFrameMerged[dataFrameMerged.click_events >= 10]\n",
    "#Rename the score column to final_mark\n",
    "dataFrameMerged = dataFrameMerged.rename(columns={'score': 'final_mark'})\n",
    "#Remove unnecessary column(s) region, final_result and highest_education\n",
    "dataFrameMerged = dataFrameMerged.drop(['region', 'final_result' ,'highest_education'], axis=1)\n",
    "print(dataFrameMerged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement FR2.8 - Write the DataFrame data to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataFrame2a = pd.read_csv(\"task2a.csv\")\n",
    "#read the 2nd file without header\n",
    "dataFrame2b = pd.read_csv(\"task2b.csv\",names=['id_student', 'click_events'], header=None) \n",
    "#using the merge function to merge the 2 dataFrames\n",
    "dataFrameMerged = pd.merge(dataFrame2a, dataFrame2b, on=['id_student'] )\n",
    "#  Remove any rows that contain missing values using dropna() function  \n",
    "dataFrameMerged.dropna()\n",
    "#Remove all rows from the DataFrame where click_event is smaller than 10  \n",
    "dataFrameMerged = dataFrameMerged[dataFrameMerged.click_events >= 10]\n",
    "#Rename the score column to final_mark\n",
    "dataFrameMerged = dataFrameMerged.rename(columns={'score': 'final_mark'})\n",
    "#Remove unnecessary column(s) region, final_result and highest_education\n",
    "dataFrameMerged = dataFrameMerged.drop(['region', 'final_result' ,'highest_education'], axis=1)\n",
    "#Write the DataFrame data to a CSV file\n",
    "# the file name is update.csv\n",
    "dataFrameMerged.to_csv(\"update.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement FR2.9 - Investigate the effects of age-group on attainment and engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#using mean from numpy to calculate the mean of final score\n",
    "df = pd.read_csv(\"update.csv\",delimiter=\"\\t\",index_col=False) \n",
    "df = df.groupby('age_band') \\\n",
    "       .agg({'final_mark':'mean'}) \\\n",
    "       .reset_index()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement FR2.10 - Present the results of the age-group investigation using an appropriate visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import table\n",
    "\n",
    "df = pd.read_csv(\"update.csv\",delimiter=\"\\t\",index_col=False) \n",
    "df = df.groupby('age_band') \\\n",
    "       .agg({'final_mark':'mean'}) \\\n",
    "       .reset_index()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "# plot chart\n",
    "ax1 = plt.subplot(121, aspect='equal')\n",
    "df.plot(kind='pie', y = 'final_mark', ax=ax1, autopct='%1.1f%%', \n",
    " startangle=90, shadow=False, labels=df['age_band'], legend = False, fontsize=14)\n",
    "\n",
    "# plot table\n",
    "ax2 = plt.subplot(122)\n",
    "plt.axis('off')\n",
    "tbl = table(ax2, df, loc='center')\n",
    "tbl.auto_set_font_size(False)\n",
    "tbl.set_fontsize(14)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement FR2.11 - Investigate the effects of engagement on attainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation: 0.314\n",
      "Pearsons correlation: 0.275\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "#Read the file update.csv\n",
    "df = pd.read_csv(\"update.csv\",delimiter=\"\\t\",index_col=False) \n",
    "#read the culumn final mark from updater.csv into a list\n",
    "col_mark_list = df['final_mark'].tolist()\n",
    "#read the culumn click_event from updater.csv into a list\n",
    "col_click_list = df['click_events'].tolist() \n",
    "# remove NaN if any\n",
    "col_click_list = np.nan_to_num(col_click_list)\n",
    "col_mark_list = np.nan_to_num(col_mark_list)\n",
    "\n",
    "#calculate the correlation betw score and Click eventa\n",
    "\n",
    "# calculate Spearman's correlation\n",
    "corr, _ = spearmanr(col_click_list, col_mark_list)\n",
    "print('Spearmans correlation: %.3f' % corr)\n",
    "\n",
    "# calculate Pearson's correlation\n",
    "corr, _ = pearsonr(col_mark_list, col_click_list)\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement FR2.12 - Test the hypothesis that there is a significant effect on attainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'update.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_1/9b2t6fys6hldmqy9gndcytpw0000gn/T/ipykernel_1077/956813889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Read the file update.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"update.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#read the culumn final mark from updater.csv into a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcol_mark_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'final_mark'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'update.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "#Read the file update.csv\n",
    "df = pd.read_csv(\"update.csv\",delimiter=\"\\t\",index_col=False) \n",
    "#read the culumn final mark from updater.csv into a list\n",
    "col_mark_list = df['final_mark'].tolist()\n",
    "#read the culumn click_event from updater.csv into a list\n",
    "col_click_list = df['click_events'].tolist() \n",
    "# remove NaN if any\n",
    "col_click_list = np.nan_to_num(col_click_list)\n",
    "col_mark_list = np.nan_to_num(col_mark_list)\n",
    "\n",
    "# Calculate the mean and the STD for both Final score and Click events\n",
    "print('Clicks Events: mean=%.3f stdv=%.3f' % (np.mean(col_click_list), np.std(col_click_list)))\n",
    "print('Final marks: mean=%.3f stdv=%.3f' % (np.mean(col_mark_list), np.std(col_mark_list)))\n",
    "\n",
    "# calculate Spearman's correlation\n",
    "corr, _ = spearmanr(col_click_list, col_mark_list)\n",
    "print('Spearmans correlation: %.3f' % corr)\n",
    "if corr < 0.5:\n",
    "       print('Based on Spearmans correlation Probably The number of Clicks Not related to Final Score')\n",
    "else:\n",
    "       print('Based on Spearmans correlation Probably The number of Clicks is related to Final Score')\n",
    "\n",
    "# calculate Pearson's correlation\n",
    "corr, _ = pearsonr(col_mark_list, col_click_list)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "if corr < 0.5:\n",
    "       print('Based on Pearson correlation Probably The number of Clicks Not related to Final Score')\n",
    "else:\n",
    "       print('Based on Pearson correlation Probably The number of Clicks is related to Final Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Development Report for Task 2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
